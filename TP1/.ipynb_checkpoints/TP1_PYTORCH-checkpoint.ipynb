{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYdUECYe2rQq"
   },
   "source": [
    "# TP 1: Get familiar with Keras and PyTorch, Multi-Layer Perceptron (MLP) and Convolutional Neural Network (CNN)\n",
    "\n",
    "## Objective of the following tutorial: Implement a MLP and a CNN on CIFAR-10 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdSCW_fCb3NM"
   },
   "source": [
    "Help:\n",
    "- https://pytorch.org/tutorials/beginner/basics/intro.html\n",
    "- https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "\n",
    "\n",
    "- [PyTorch official website](https://pytorch.org/)\n",
    "- [PyTorch Lightning](https://www.pytorchlightning.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy0NTyiL2rQr"
   },
   "source": [
    "## 1. Example with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9KgNiKq2rQs"
   },
   "source": [
    "### a) Load the useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyQLN4h12rQs"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np # manipulate N-dimensional arrays\n",
    "import pandas as pd # data frame\n",
    "import matplotlib.pyplot as plt # data plotting\n",
    "import seaborn # advanced data plotting\n",
    "from sklearn import preprocessing # basic ML models\n",
    "# import scipy # scientific computing library\n",
    "\n",
    "import os\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtD-94_hLGh-"
   },
   "source": [
    "Check the version of Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFAsxLcxJE38"
   },
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOcHamIzLanK"
   },
   "source": [
    "Check if you can use a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLbgVk0NLvaP"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siK1R4mi2rQv"
   },
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6J7t3PbPW9U2"
   },
   "source": [
    "Set the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXykerxSW3ks"
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # 0 indicates the GPU ID you will use\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAdKlI0Y5_ut"
   },
   "source": [
    "If you have several GPUs, please refer to the specific GPU ID you want to use: by default the first GPU has always the ID \"0\" and then, the ID can be \"1\", \"2\", ...etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSe4u_QH2rQ5"
   },
   "source": [
    "### b) Load and Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDAJo51DOz3z"
   },
   "source": [
    "The data can be directly downloaded with PyTorch. Please visit the following website: https://pytorch.org/vision/stable/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEGEPlSz2rQ6"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiVg7qS8eeM-"
   },
   "source": [
    "Note that Pytorch recommends using their newest version `torchvision.transforms.v2` wich is faster and holds more function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jngi0lmF2rQ6"
   },
   "outputs": [],
   "source": [
    "# # With data images, the preprocess must be declared before loading the data\n",
    "# set the transformation as a composition of several preprocessing\n",
    "\n",
    "# Exemple of centering and reduction: (X_i- X_mean)/X_std\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))]) # delete this line to perform MinMaxScaler /!\\ must be achieved on raw data\n",
    "# note that only standard scaler is available in PyTorch, you can create a class MinMaxScaler that inheritates from transforms to be included in the pipeline transforms\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbNJpp6O24hY"
   },
   "outputs": [],
   "source": [
    "classes = dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdhORwvaZDOA"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p62l4EZhSoDS"
   },
   "outputs": [],
   "source": [
    "dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6In4Ef-Lm6iZ"
   },
   "outputs": [],
   "source": [
    "class_count = {}\n",
    "for _, index in dataset:\n",
    "    label = classes[index]\n",
    "    if label not in class_count:\n",
    "        class_count[label] = 0\n",
    "    class_count[label] += 1\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwGr5DeIS5zd"
   },
   "outputs": [],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSh6xaPOglNG"
   },
   "outputs": [],
   "source": [
    "dataset.data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCaD70n1VO0M"
   },
   "source": [
    "Additionnal steps to:\n",
    "- split the trainset into a train and validation set.\n",
    "\n",
    "Have a look on https://pytorch.org/docs/stable/data.html. <br>\n",
    "You can easily create your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKeMDau9Senu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 42 #for reproductible results\n",
    "train_indices, val_indices = train_test_split(list(range(len(dataset.targets))),\n",
    "                                              test_size=10000,\n",
    "                                              stratify=dataset.targets,\n",
    "                                              random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIAfyS0sXqTZ"
   },
   "source": [
    "Another possibility is to use the random_split but the proportions will not be kept. Note that the more samples you use, the lower the likelihood of creating an imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORqpaPN7YMoI"
   },
   "outputs": [],
   "source": [
    "# trainset,valset = torch.utils.data.random_split(trainset, [40000,10000],generator=torch.Generator().manual_seed(random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9rUPfnnTb8F"
   },
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.Subset(dataset, train_indices)\n",
    "valset = torch.utils.data.Subset(dataset, val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7fD1kbxVjQN"
   },
   "source": [
    "Only once the additionnal steps are performed, you can use the dataloader that will split the dataset into batches. Remember that, in Keras, this was done automatically when we injected the training data into the `model.fit()` function.\n",
    "\n",
    "Here, with Pytorch, we can custom our dataloaders especially to optimize training time using arguments like `num_workers`, `prefetch_factor`...etc. See the documentation: https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPwI3Vj4UPPn"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-JBisRznhMu"
   },
   "source": [
    "Vizualize a grid of images <br>\n",
    "Help: https://pytorch.org/vision/stable/auto_examples/plot_visualization_utils.html#visualizing-a-grid-of-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIHMNO3y0SFe"
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "for images, _ in testloader:\n",
    "    print('images.shape:', images.shape)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(make_grid(images, nrow=8).permute((1, 2, 0)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2R4Y8TsKiXlS"
   },
   "source": [
    "We can see that images cannot be fully visualized because the normalization we applied causes some pixels to be of negative values.\n",
    "To visualize correctly, we can unnormalize.\n",
    "\n",
    "Does this happen with MinMax normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eP2waA8QiuLW"
   },
   "outputs": [],
   "source": [
    "#normalization: y = (x-mean)/std\n",
    "mean = torch.tensor([0.5, 0.5, 0.5], dtype=torch.float32)\n",
    "std = torch.tensor([0.5, 0.5, 0.5], dtype=torch.float32)\n",
    "unnormalize = transforms.Normalize((-mean / std).tolist(), (1.0 / std).tolist()) #to get the data unnormalized, you must invert normalization to cumpute x = y*std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSnqAnAPeoFx"
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "for images, _ in testloader:\n",
    "    print('images.shape:', images.shape)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(make_grid(unnormalize(images), nrow=8).permute((1, 2, 0)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnJ624xyQMWO"
   },
   "source": [
    "### c) Implement the CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6rTkfNUQMWO"
   },
   "source": [
    "Convert the model implemented in Keras into PyTorch <br>\n",
    "Help:\n",
    "- https://pytorch.org/docs/stable/nn.functional.html\n",
    "- [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "- [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)\n",
    "- [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)\n",
    "- [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoDayEnXjz8w"
   },
   "source": [
    "Here, we define our model as a class object with properties like layers, activation functions...etc and always a `forward` function that is called for any forward pass through the model.\n",
    "\n",
    "In the Pytorch documentation, authors describe `nn.Module` as:\n",
    "\n",
    "\"*Base class for all neural network modules. **Your models should also subclass this class.** Modules can also contain other Modules, allowing to nest them in a tree structure.*\"\n",
    "\n",
    "Check this documentation to understand how to design your models using pytorch `nn.Module`: https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9u9gPCCRY2VX"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # always subclass\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=\"same\") # first conv layer\n",
    "        # the three arguments in_channels, out_channels, kernel_size must be filled, the others are optionnal and have default values\n",
    "        # out_channels correspond to the number of filters\n",
    "        # if heigth=width in the kernel size, just set one value instead of a tuple\n",
    "        # stride is set to 1 by default\n",
    "        # padding='same' pads the input so the output has the shape as the input. However, this mode doesnâ€™t support any stride values other than 1.\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3,padding=\"same\") # second conv layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2) # maxpooling\n",
    "        self.dp1 = nn.Dropout(p=0.25)\n",
    "        self.fc1 = nn.Linear(in_features=32 * 16 * 16, out_features=512) # linear layer after flattening\n",
    "        self.dp2 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=10) # we have 10 probability classes to predict so 10 output features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dp1(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.dp2(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    # This is the same forward pass as the one commented below. When starting in Pytorch, it can be better to write sequentially every\n",
    "    # pass in the forward pass to be sure to understand if every layer is at the right place.\n",
    "\n",
    "    # def forward(self, x):\n",
    "      # x = self.conv1(x)\n",
    "      # x = F.relu(x)\n",
    "      # x = self.conv2(x)\n",
    "      # x = F.relu(x)\n",
    "      # x = self.pool(x)\n",
    "      # x = self.dp1(x)\n",
    "      # x = torch.flatten(x, 1)\n",
    "      # x = self.fc1(x)\n",
    "      # x = F.relu(x)\n",
    "      # x = self.dp2(x)\n",
    "      # x = self.fc2(x)\n",
    "      # return x\n",
    "\n",
    "net = Net().to(device) # train on GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSehAPKEsgud"
   },
   "outputs": [],
   "source": [
    "print(net) # similar to `model.summary` in keras\n",
    "print(\"(model mem allocation) - Memory available : {:.2e}\".format(torch.cuda.memory_reserved(0)-torch.cuda.memory_allocated(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJClx-VXSc_H"
   },
   "outputs": [],
   "source": [
    "# Find total parameters and trainable parameters\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "print(\"{} total parameters.\".format(total_params))\n",
    "total_trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(\"{} training parameters.\".format(total_trainable_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bcVK4zorwLK"
   },
   "source": [
    "How do we keep track of the image sizes after convolutions, poolings and padding ?\n",
    "\n",
    "Pytorch documentation displays the equations to compute the image size.\n",
    "Check the documentation of each layer!\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d\n",
    "\n",
    "It is the same equation for Conv2D and MaxPooling2D :\n",
    "\n",
    "$H_{out} = \\frac{H_{in} + 2padding - dilation*(kernel - 1) - 1}{stride} + 1$\n",
    "$W_{out} = \\frac{W_{in} + 2padding - dilation*(kernel - 1) - 1}{stride} + 1$\n",
    "\n",
    "If `padding='same'`, the output image after the convolution layer will be the same size as the input image.\n",
    "Let's perform a safety check below using the equation provided by pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7enFdiNLrxkI"
   },
   "outputs": [],
   "source": [
    "# Function to compute size after conv2D layer or maxpooling 2D layer and to compute the value of padding when using padding='same'\n",
    "\n",
    "def func_output_size(input_size, padding=0, stride=1, dilation=1, kernel_size=None):\n",
    "  return (input_size + 2*padding - dilation*(kernel_size-1) - 1)/stride + 1\n",
    "\n",
    "def func_same_padding_value(input_size, stride=1, dilation=1, kernel_size=None):\n",
    "  return ((input_size-1)*stride + 1 - input_size + dilation*(kernel_size-1))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4ygyln3rxVh"
   },
   "outputs": [],
   "source": [
    "pad = func_same_padding_value(32, stride=1, dilation=1, kernel_size=3)\n",
    "print(pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDpicyshrxR0"
   },
   "outputs": [],
   "source": [
    "size = func_output_size(input_size=32, padding=pad, kernel_size=3, stride = 1, dilation=1)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgeRt-oku1yN"
   },
   "source": [
    "You should find an output size of 32 which corresponds to the input size of our images (32x32 since we have squared images) which is precisely what we wanted using `padding=same`.\n",
    "\n",
    "Now, let's track the size of images and feature maps through the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27p0r0-quzPD"
   },
   "outputs": [],
   "source": [
    "# We use 2 conv2d layers with padding='same' meaning that our feature maps are still of size 32x32 after these layers.\n",
    "print(f\"Size after 1st Conv2D layer: ({size}, {size})\")\n",
    "print(f\"Size after 2nd Conv2D layer: ({size}, {size})\")\n",
    "# Then we use a maxpooling layer\n",
    "size_after_pooling = func_output_size(input_size=32, padding=0, kernel_size=2, stride = 2, dilation=1)\n",
    "print(f\"Size after MaxPooling2D layer: ({size_after_pooling}, {size_after_pooling})\")\n",
    "# At this point we have specified 32 squared filters, therefore, if we flatten our images we end up multiplying all dimensions (CxHxW):\n",
    "print(f\"Size after flattening: {32*size_after_pooling*size_after_pooling}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLoJM3uEu7cB"
   },
   "source": [
    "This fits what we obtained when printing the model (`print(net)`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bypu9ips6I0"
   },
   "source": [
    "#### Set the criterion and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXsuk2S7s7Ah"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "output_fn = torch.nn.Softmax(dim=1) # we instantiate the softmax activation function for the output probabilities\n",
    "criterion = nn.CrossEntropyLoss() # we instantiate the loss function\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) # we instantiate Adam optimizer that takes as inputs the model parameters and learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqDe5C9OwtHc"
   },
   "source": [
    "/!\\ The `nn.CrossEntropyLoss()` function takes as inputs non normalized predictions (before a sigmoid or softmax activation function for instance).\n",
    "Check the documentation: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "\n",
    "The targets to predict should not necessarily be one-hot encoded this time.\n",
    "\n",
    "**label_smoothing**: smoothes the target labels to intermediate values instead of hard probabilities of 0 and 1: \"The targets become a mixture of the original ground truth and a uniform distribution.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PO8rGyMLutAI"
   },
   "outputs": [],
   "source": [
    "# Compared to keras, we need to instantiate our performance metric\n",
    "def get_accuracy(y_true, y_pred):\n",
    "    return int(np.sum(np.equal(y_true,y_pred))) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bah7AlzH4_Tj"
   },
   "source": [
    "Launch the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7L7DXtyhBBdp"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFusgmnxsemv"
   },
   "outputs": [],
   "source": [
    "# Init\n",
    "epochs = 2\n",
    "output_fn = torch.nn.Softmax(dim=1) # we instantiate the softmax activation function for the output probabilities\n",
    "criterion = nn.CrossEntropyLoss() # we instantiate the loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # we instantiate Adam optimizer that takes as inputs the model parameters and learning rate\n",
    "\n",
    "loss_valid,acc_valid =[],[]\n",
    "loss_train,acc_train =[],[]\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "  # Training loop\n",
    "  net.train() # always specify that the model is in training mode\n",
    "  running_loss = 0.0 # init loss\n",
    "  running_acc = 0.\n",
    "\n",
    "  # Loop over batches returned by the data loader\n",
    "  for idx, batch in enumerate(trainloader):\n",
    "\n",
    "    # get the inputs; batch is a tuple of (inputs, labels)\n",
    "    inputs, labels = batch\n",
    "    inputs = inputs.to(device) # put the data on the same device as the model\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # put to zero the parameters gradients at each iteration to avoid accumulations\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward pass + backward pass + update the model parameters\n",
    "    out = net(x=inputs) # get predictions\n",
    "    loss = criterion(out, labels) # compute loss\n",
    "    loss.backward() # compute gradients\n",
    "    optimizer.step() # update model parameters according to these gradients and our optimizer strategy\n",
    "\n",
    "    # Iteration train metrics\n",
    "    running_loss += loss.view(1).item()\n",
    "    t_out = output_fn(out.detach()).cpu().numpy() # compute softmax (previously instantiated) and detach predictions from the model graph\n",
    "    t_out=t_out.argmax(axis=1)  # the class with the highest energy is what we choose as prediction\n",
    "    ground_truth = labels.cpu().numpy() # detach the labels from GPU device\n",
    "    running_acc += get_accuracy(ground_truth, t_out)\n",
    "\n",
    "  ### Epochs train metrics ###\n",
    "  acc_train.append(running_acc/len(trainloader))\n",
    "  loss_train.append(running_loss/len(trainloader))\n",
    "\n",
    "  # compute loss and accuracy after an epoch on the train and valid set\n",
    "  net.eval() # put the model in evaluation mode (this prevents the use of dropout layers for instance)\n",
    "\n",
    "  ### VALIDATION DATA ###\n",
    "  with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    idx = 0\n",
    "    for batch in valloader:\n",
    "      inputs,labels=batch\n",
    "      inputs=inputs.to(device)\n",
    "      labels=labels.to(device)\n",
    "      if idx==0:\n",
    "        t_out = net(x=inputs)\n",
    "        t_loss = criterion(t_out, labels).view(1).item()\n",
    "        t_out = output_fn(t_out).detach().cpu().numpy() # compute softmax (previously instantiated) and detach predictions from the model graph\n",
    "        t_out=t_out.argmax(axis=1)  # the class with the highest energy is what we choose as prediction\n",
    "        ground_truth = labels.cpu().numpy() # detach the labels from GPU device\n",
    "      else:\n",
    "        out = net(x=inputs)\n",
    "        t_loss = np.hstack((t_loss,criterion(out, labels).item()))\n",
    "        t_out = np.hstack((t_out,output_fn(out).argmax(axis=1).detach().cpu().numpy()))\n",
    "        ground_truth = np.hstack((ground_truth,labels.detach().cpu().numpy()))\n",
    "      idx+=1\n",
    "\n",
    "    acc_valid.append(get_accuracy(ground_truth,t_out))\n",
    "    loss_valid.append(np.mean(t_loss))\n",
    "\n",
    "  print('| Epoch: {}/{} | Train: Loss {:.4f} Accuracy : {:.4f} '\\\n",
    "      '| Val: Loss {:.4f} Accuracy : {:.4f}\\n'.format(epoch+1,epochs,loss_train[epoch],acc_train[epoch],loss_valid[epoch],acc_valid[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t75LJ_-K3Z65"
   },
   "outputs": [],
   "source": [
    "# Write the training loop in a function you can re use\n",
    "\n",
    "def train_model(model, epochs, train_loader, val_loader, device=None):\n",
    "  ...\n",
    "  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpaXUyWZB_E7"
   },
   "outputs": [],
   "source": [
    "# Train the model using your function\n",
    "\n",
    "... = train_model(net, 25, trainloader, valloader, device=device) #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4X3I-jmz5Hfx"
   },
   "source": [
    "Save the model -> useful latter for transfer learning <br>\n",
    "Help: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ndwn9OP5G08"
   },
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bAu5eqY3_bh"
   },
   "source": [
    "### d) Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_qgOwUb5dm3"
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "  idx = 0\n",
    "  for batch in testloader:\n",
    "    inputs,labels=batch\n",
    "    ...\n",
    "    #TODO\n",
    "\n",
    "print(\"Test accuracy {}\".format(get_accuracy(ground_truth,t_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPmXzGOQ4qHJ"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVvYofl44qDw"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues, size=15):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    :param cm: (numpy matrix) confusion matrix\n",
    "    :param classes: [str]\n",
    "    :param normalize: (bool)\n",
    "    :param title: (str)\n",
    "    :param cmap: (matplotlib color map)\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(size,size+2))\n",
    "    im = plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, size=18, family='serif')\n",
    "    cb = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    cb.ax.tick_params(labelsize=14)\n",
    "    #Set the font type and size of the colorbar\n",
    "    for l in cb.ax.yaxis.get_ticklabels():\n",
    "        l.set_family(\"serif\")\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontname='serif', size=14)\n",
    "    plt.yticks(tick_marks, classes, fontname='serif', size=14)\n",
    "\n",
    "    fmt = '.1f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 family='serif',\n",
    "                 size=12)\n",
    "\n",
    "\n",
    "    plt.ylabel('True label', size=18, fontname='serif')\n",
    "    plt.xlabel('Predicted label', size=18, fontname='serif')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1HIRHCC4qA1"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(..., ...) # confusion matrix # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phttl3CG4p9l"
   },
   "outputs": [],
   "source": [
    "LABELS = {\n",
    "    0 : \"airplane\",\n",
    "    1 : \"automobile\",\n",
    "    2 : \"bird\",\n",
    "    3 : \"cat\",\n",
    "    4 : \"deer\",\n",
    "    5 : \"dog\",\n",
    "    6 : \"frog\",\n",
    "    7 : \"horse\",\n",
    "    8 : \"ship\",\n",
    "    9 : \"truck\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CIiOwQb4zlM"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, LABELS.values(),\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues, size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hadX-nDJ43mb"
   },
   "outputs": [],
   "source": [
    "# Report\n",
    "\n",
    "print(classification_report(..., ..., target_names=LABELS.values())) #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naJdk-gp41x2"
   },
   "source": [
    "## 2. Build your own CNN !\n",
    "\n",
    "### Objectives:\n",
    "- Adjust the CNN on the validation set to get the best performances. Play with the hyperparameters. Analyze and comment your results.\n",
    "- Learn the final model on the full training data and test on the test data\n",
    "\n",
    "----> Use the functions we defined above in the notebook\n",
    "\n",
    "----> Instantiate a new model every time you want to train an architecture again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoIDESAK5K42"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JQrL0tjCsPe"
   },
   "outputs": [],
   "source": [
    "# You can build your own callbacks like EarlyStopping for instance:\n",
    "\n",
    "class EarlyStopper():\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0m0MuUwwC1Y_"
   },
   "source": [
    "Check the documentation for built-in learning rate schedulers:\n",
    "\n",
    "- https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LinearLR.html#torch.optim.lr_scheduler.LinearLR\n",
    "\n",
    "- https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR\n",
    "\n",
    "- https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9C73JZMDdnU"
   },
   "source": [
    "For data augmentation, check again the transforms documentation: https://pytorch.org/vision/stable/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHejy27zDe8o"
   },
   "outputs": [],
   "source": [
    "# Change transforms to add augmentation\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hastzFidWNiE"
   },
   "source": [
    "For further optimization, check the Optuna package: https://optuna.readthedocs.io/en/stable/index.html\n",
    "\n",
    "Read: https://medium.com/pytorch/using-optuna-to-optimize-pytorch-hyperparameters-990607385e36\n",
    "\n",
    "- You can specify the metric you want to optimize (accuracy, f1_score...etc)\n",
    "- You write your own objective function\n",
    "- You specify the search type: grid, random or bayesian for instance.\n",
    "- You specify the number of trials\n",
    "- You can retrieve all the search results and best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NN9vH39fWpHa"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # TODO\n",
    "    # objective function to run at each trial.\n",
    "\n",
    "    # Specify the hyperparameters to search, their type and the value range:\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-1)\n",
    "    ...\n",
    "\n",
    "    # Train the model\n",
    "    model.train()...\n",
    "\n",
    "    # Must return the metric you want to maximize or minimize.\n",
    "    return metric\n",
    "\n",
    "# Create a search study\n",
    "study = optuna.create_study()\n",
    "# Run the search\n",
    "study.optimize(objective, n_trials=..., )\n",
    "# Check best params\n",
    "study.best_params"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1aWQjndWKekyDD4b_fshdzkNt1FK8WdqY",
     "timestamp": 1638817299424
    },
    {
     "file_id": "13PSbHn2E1wAlVMD2duRgMAimlDL9y1Qh",
     "timestamp": 1608191971960
    },
    {
     "file_id": "1w3e3JzzUXKFzQeQrq0AFznPLBs3J7YhY",
     "timestamp": 1607028152797
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
